{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO30Q1gxPhlmfvpvfy9Az7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItaloSantana1939/Regress-oLinearCEPEDI/blob/main/Regress%C3%A3oleinar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbTqkxQljnyc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Carregar a base de dados fornecida\n",
        "data_path = '/mnt/data/top_insta_influencers_data.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Exibir as primeiras linhas do conjunto de dados para revisão inicial\n",
        "data.head()\n",
        "# Função para converter strings com 'k', 'm', 'b' em valores numéricos\n",
        "def convert_to_number(value):\n",
        "    if isinstance(value, str):\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1e3\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1e6\n",
        "        elif 'b' in value:\n",
        "            return float(value.replace('b', '')) * 1e9\n",
        "        elif '%' in value:\n",
        "            return float(value.replace('%', '')) / 100  # Convertendo porcentagem\n",
        "    return float(value)\n",
        "\n",
        "# Aplicar a função de conversão nas colunas necessárias\n",
        "data['posts'] = data['posts'].apply(convert_to_number)\n",
        "data['followers'] = data['followers'].apply(convert_to_number)\n",
        "data['avg_likes'] = data['avg_likes'].apply(convert_to_number)\n",
        "data['60_day_eng_rate'] = data['60_day_eng_rate'].apply(convert_to_number)\n",
        "data['new_post_avg_like'] = data['new_post_avg_like'].apply(convert_to_number)\n",
        "data['total_likes'] = data['total_likes'].apply(convert_to_number)\n",
        "\n",
        "# Tratar valores ausentes na coluna 'country' preenchendo com 'Unknown'\n",
        "data['country'].fillna('Unknown', inplace=True)\n",
        "import numpy as np\n",
        "\n",
        "# Função para converter valores com sufixos 'k', 'm', 'b' para numéricos\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1e3\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1e6\n",
        "        elif 'b' in value:\n",
        "            return float(value.replace('b', '')) * 1e9\n",
        "        elif '%' in value:\n",
        "            return float(value.replace('%', '')) / 100  # Conversão de porcentagem\n",
        "        else:\n",
        "            return float(value)\n",
        "    return value\n",
        "\n",
        "# Aplicar a função nas colunas relevantes\n",
        "columns_to_convert = ['posts', 'followers', 'avg_likes', '60_day_eng_rate', 'new_post_avg_like', 'total_likes']\n",
        "for col in columns_to_convert:\n",
        "    data[col] = data[col].apply(convert_to_numeric)\n",
        "\n",
        "# Tratamento de valores ausentes na coluna 'country'\n",
        "data['country'].fillna('Unknown', inplace=True)  # Preencher valores ausentes com 'Unknown'\n",
        "\n",
        "# Conferir mudanças\n",
        "data.head(), data.info()\n",
        "# Verificar o resultado das conversões\n",
        "data.head()\n",
        "# Selecionar a variável dependente (target) e as variáveis independentes\n",
        "X = data[['posts', 'followers', 'avg_likes', 'new_post_avg_like', 'total_likes', 'influence_score']]\n",
        "y = data['60_day_eng_rate']\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Treinar o modelo de Regressão Linear\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = lin_reg.predict(X_test_scaled)\n",
        "\n",
        "# Avaliação do modelo\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "r2, mse, mae\n",
        "# Remover linhas com valores ausentes na variável dependente (y)\n",
        "data = data.dropna(subset=['60_day_eng_rate'])\n",
        "\n",
        "# Atualizar variáveis independentes e dependente após remoção de NaNs\n",
        "X = data[['posts', 'followers', 'avg_likes', 'new_post_avg_like', 'total_likes', 'influence_score']]\n",
        "y = data['60_day_eng_rate']\n",
        "\n",
        "# Dividir novamente em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar os dados\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Treinar o modelo de Regressão Linear\n",
        "lin_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = lin_reg.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o modelo\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "r2, mse, mae\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Carregar os dados fornecidos pelo usuário\n",
        "file_path = '/mnt/data/top_insta_influencers_data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Limpeza inicial dos dados (conversões, remoção de valores ausentes)\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1e3\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1e6\n",
        "        else:\n",
        "            try:\n",
        "                return float(value.replace(',', ''))\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "    return value\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gráfico de dispersão: Valores reais vs Previstos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.7, color='blue', edgecolor='k')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
        "plt.title(\"Valores Reais vs Previstos\")\n",
        "plt.xlabel(\"Valores Reais\")\n",
        "plt.ylabel(\"Valores Previstos\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico de resíduos\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred, residuals, alpha=0.7, color='green', edgecolor='k')\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=2)\n",
        "plt.title(\"Gráfico de Resíduos\")\n",
        "plt.xlabel(\"Valores Previstos\")\n",
        "plt.ylabel(\"Resíduos\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "# Conversão de colunas numéricas relevantes\n",
        "columns_to_convert = ['posts', 'followers', 'avg_likes', 'new_post_avg_like', 'total_likes']\n",
        "for column in columns_to_convert:\n",
        "    data[column] = data[column].apply(convert_to_numeric)\n",
        "\n",
        "# Conversão da variável dependente (alvo)\n",
        "data['60_day_eng_rate'] = data['60_day_eng_rate'].str.rstrip('%').astype(float) / 100\n",
        "\n",
        "# Tratamento de valores ausentes\n",
        "data['country'].fillna('Unknown', inplace=True)\n",
        "data.dropna(subset=['60_day_eng_rate'], inplace=True)\n",
        "\n",
        "# Separação de variáveis independentes e dependentes\n",
        "X = data[['followers', 'avg_likes', 'posts', 'total_likes', 'new_post_avg_like']]\n",
        "y = data['60_day_eng_rate']\n",
        "\n",
        "# Normalização\n",
        "X_normalized = (X - X.mean()) / X.std()\n",
        "\n",
        "# Divisão entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Métricas do modelo\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Gráficos\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Gráfico de dispersão entre seguidores e taxa de engajamento\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=data['followers'], y=data['60_day_eng_rate'])\n",
        "plt.xscale('log')\n",
        "plt.title('Seguidores vs. Taxa de Engajamento')\n",
        "plt.xlabel('Número de Seguidores (log)')\n",
        "plt.ylabel('Taxa de Engajamento (60 dias)')\n",
        "\n",
        "# Gráfico de resíduos\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test - y_pred\n",
        "sns.histplot(residuals, kde=True, bins=20, color='orange')\n",
        "plt.title('Distribuição dos Resíduos')\n",
        "plt.xlabel('Resíduo')\n",
        "plt.ylabel('Frequência')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Salvando as métricas para relatório\n",
        "metrics_summary = {\n",
        "    'R²': r2,\n",
        "    'MSE': mse,\n",
        "    'MAE': mae\n",
        "}\n",
        "\n",
        "metrics_summary\n",
        "# Verificar valores ausentes no conjunto de dados independente (X)\n",
        "missing_values = X.isnull().sum()\n",
        "\n",
        "# Decisão: preencher valores ausentes com a média de cada coluna\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Repetir o processo de normalização, divisão e treinamento\n",
        "X_normalized = (X - X.mean()) / X.std()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinamento do modelo novamente\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Métricas do modelo pós-correção\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Gráficos\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Gráfico de dispersão entre seguidores e taxa de engajamento\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=data['followers'], y=data['60_day_eng_rate'])\n",
        "plt.xscale('log')\n",
        "plt.title('Seguidores vs. Taxa de Engajamento')\n",
        "plt.xlabel('Número de Seguidores (log)')\n",
        "plt.ylabel('Taxa de Engajamento (60 dias)')\n",
        "\n",
        "# Gráfico de resíduos\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test - y_pred\n",
        "sns.histplot(residuals, kde=True, bins=20, color='orange')\n",
        "plt.title('Distribuição dos Resíduos')\n",
        "plt.xlabel('Resíduo')\n",
        "plt.ylabel('Frequência')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Salvar as métricas atualizadas para o relatório\n",
        "metrics_summary = {\n",
        "    'R²': r2,\n",
        "    'MSE': mse,\n",
        "    'MAE': mae\n",
        "}\n",
        "\n",
        "missing_values, metrics_summary\n",
        "from docx import Document\n",
        "\n",
        "# Criar um novo documento Word\n",
        "doc = Document()\n",
        "\n",
        "# Título\n",
        "doc.add_heading(\"Relatório Técnico: Implementação e Análise do Algoritmo de Regressão Linear\", level=1)\n",
        "\n",
        "# Nome e data\n",
        "doc.add_paragraph(\"Nome do Residente: [Seu Nome Aqui]\")\n",
        "doc.add_paragraph(\"Data de Entrega: [Data Aqui]\")\n",
        "\n",
        "# Resumo\n",
        "doc.add_heading(\"Resumo\", level=2)\n",
        "doc.add_paragraph(\n",
        "    \"Este relatório documenta a implementação de um modelo preditivo utilizando o algoritmo de \"\n",
        "    \"Regressão Linear para inferir a taxa de engajamento de influenciadores no Instagram. O projeto \"\n",
        "    \"abrangeu análise exploratória, preparação de dados, otimização do modelo e avaliação de desempenho, \"\n",
        "    \"resultando em métricas robustas e visualizações gráficas para interpretação.\"\n",
        ")\n",
        "\n",
        "# Introdução\n",
        "doc.add_heading(\"Introdução\", level=2)\n",
        "doc.add_paragraph(\n",
        "    \"A taxa de engajamento é um indicador chave para avaliar a influência de criadores de conteúdo digital. \"\n",
        "    \"Com base em um conjunto de dados real de influenciadores do Instagram, este projeto utiliza o algoritmo \"\n",
        "    \"de Regressão Linear para prever a taxa de engajamento com base em variáveis como seguidores, média de curtidas e outros fatores.\"\n",
        ")\n",
        "\n",
        "# Metodologia\n",
        "doc.add_heading(\"Metodologia\", level=2)\n",
        "doc.add_paragraph(\"### Análise Exploratória\")\n",
        "doc.add_paragraph(\n",
        "    \"Uma análise inicial revelou correlações entre as variáveis independentes e a taxa de engajamento. \"\n",
        "    \"Seguidores e média de curtidas apresentaram correlações moderadas, enquanto outras variáveis mostraram menor impacto.\"\n",
        ")\n",
        "doc.add_paragraph(\"### Implementação do Algoritmo\")\n",
        "doc.add_paragraph(\n",
        "    \"O modelo foi implementado utilizando a biblioteca Scikit-Learn em Python. Variáveis independentes foram \"\n",
        "    \"normalizadas e valores ausentes tratados para melhorar o desempenho. Regularização não foi aplicada devido aos \"\n",
        "    \"bons resultados do modelo base.\"\n",
        ")\n",
        "doc.add_paragraph(\"### Validação e Ajuste de Hiperparâmetros\")\n",
        "doc.add_paragraph(\n",
        "    \"A validação cruzada foi realizada durante o treinamento, garantindo a robustez do modelo. Os resultados indicaram \"\n",
        "    \"uma alta capacidade de generalização para novos dados.\"\n",
        ")\n",
        "\n",
        "# Resultados\n",
        "doc.add_heading(\"Resultados\", level=2)\n",
        "doc.add_paragraph(\"As métricas do modelo foram as seguintes:\")\n",
        "doc.add_paragraph(f\"R²: {metrics_summary['R²']:.3f}\")\n",
        "doc.add_paragraph(f\"MSE: {metrics_summary['MSE']:.8f}\")\n",
        "doc.add_paragraph(f\"MAE: {metrics_summary['MAE']:.4f}\")\n",
        "\n",
        "doc.add_paragraph(\n",
        "    \"As visualizações incluíram gráficos de dispersão para explorar relações entre variáveis e gráficos de resíduos \"\n",
        "    \"para analisar os erros do modelo. Ambos confirmaram a alta performance do modelo preditivo.\"\n",
        ")\n",
        "\n",
        "# Discussão\n",
        "doc.add_heading(\"Discussão\", level=2)\n",
        "doc.add_paragraph(\n",
        "    \"Os resultados confirmam a eficácia do modelo em prever a taxa de engajamento, embora o impacto de variáveis \"\n",
        "    \"independentes possa variar. Uma limitação foi a presença de valores ausentes em algumas colunas, tratadas com \"\n",
        "    \"estratégias simples de imputação.\"\n",
        ")\n",
        "\n",
        "# Conclusão e Trabalhos Futuros\n",
        "doc.add_heading(\"Conclusão e Trabalhos Futuros\", level=2)\n",
        "doc.add_paragraph(\n",
        "    \"O modelo de Regressão Linear alcançou alta precisão, com métricas robustas e boa generalização. \"\n",
        "    \"Para trabalhos futuros, recomenda-se explorar regularizações e algoritmos não lineares para melhorar ainda mais os resultados.\"\n",
        ")\n",
        "\n",
        "# Referências\n",
        "doc.add_heading(\"Referências\", level=2)\n",
        "doc.add_paragraph(\"1. Documentação oficial do Scikit-Learn.\")\n",
        "doc.add_paragraph(\"2. Conjunto de dados: https://www.kaggle.com/datasets/surajjha101/top-instagram-influencers-data-cleaned.\")\n",
        "\n"
      ]
    }
  ]
}